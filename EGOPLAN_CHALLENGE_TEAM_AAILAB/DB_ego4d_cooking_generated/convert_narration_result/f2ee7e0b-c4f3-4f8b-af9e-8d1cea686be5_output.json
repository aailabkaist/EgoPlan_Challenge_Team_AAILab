[
    {
        "task_goal": "Cleaning the kitchen area",
        "task_progress_metadata": [
            {
                "narration_text": "Picks a clothing on the kitchen table",
                "start_frame": 27,
                "stop_frame": 49
            },
            {
                "narration_text": "Drops the clothing on a plastic tray on the table",
                "start_frame": 49,
                "stop_frame": 66
            },
            {
                "narration_text": "Picks unsure on the kitchen table",
                "start_frame": 66,
                "stop_frame": 87
            },
            {
                "narration_text": "Cleans the kitchen table with a cloth",
                "start_frame": 87,
                "stop_frame": 113
            },
            {
                "narration_text": "Drops the dust on the cloth in the bin",
                "start_frame": 113,
                "stop_frame": 119
            },
            {
                "narration_text": "Shakes the cloth on top of the dust bin",
                "start_frame": 119,
                "stop_frame": 184
            },
            {
                "narration_text": "Cleans the kitchen table with a cloth",
                "start_frame": 184,
                "stop_frame": 264
            },
            {
                "narration_text": "Cleans the cooker on top of the table",
                "start_frame": 264,
                "stop_frame": 388
            },
            {
                "narration_text": "Drops the cloth on the kitchen table",
                "start_frame": 388,
                "stop_frame": 404
            },
            {
                "narration_text": "Drops unsure on the cooker",
                "start_frame": 404,
                "stop_frame": 424
            },
            {
                "narration_text": "Picks the cloth on top of the plastic tray on the table",
                "start_frame": 424,
                "stop_frame": 460
            },
            {
                "narration_text": "Places the cloth on the kitchen table",
                "start_frame": 460,
                "stop_frame": 470
            },
            {
                "narration_text": "Picks the cloth on the kitchen table",
                "start_frame": 470,
                "stop_frame": 493
            },
            {
                "narration_text": "Moves to the sink",
                "start_frame": 493,
                "stop_frame": 540
            },
            {
                "narration_text": "Opens the tap",
                "start_frame": 540,
                "stop_frame": 560
            },
            {
                "narration_text": "Washes the cloth in the sink",
                "start_frame": 560,
                "stop_frame": 787
            },
            {
                "narration_text": "Rinses the cloth in the sink",
                "start_frame": 787,
                "stop_frame": 872
            },
            {
                "narration_text": "Rinses his hand in the sink",
                "start_frame": 872,
                "stop_frame": 967
            }
        ]
    },
    {
        "task_goal": "Picking up and placing items on the kitchen table",
        "task_progress_metadata": [
            {
                "narration_text": "Picks a clothing on the kitchen table",
                "start_frame": 27,
                "stop_frame": 49
            },
            {
                "narration_text": "Drops the clothing on a plastic tray on the table",
                "start_frame": 49,
                "stop_frame": 66
            },
            {
                "narration_text": "Picks unsure on the kitchen table",
                "start_frame": 66,
                "stop_frame": 87
            }
        ]
    },
    {
        "task_goal": "Cleaning the kitchen table",
        "task_progress_metadata": [
            {
                "narration_text": "Drops the clothing on a plastic tray on the table",
                "start_frame": 49,
                "stop_frame": 66
            },
            {
                "narration_text": "Picks unsure on the kitchen table",
                "start_frame": 66,
                "stop_frame": 87
            },
            {
                "narration_text": "Cleans the kitchen table with a cloth",
                "start_frame": 87,
                "stop_frame": 113
            },
            {
                "narration_text": "Drops the dust on the cloth in the bin",
                "start_frame": 113,
                "stop_frame": 119
            }
        ]
    },
    {
        "task_goal": "Disposing of dust in the bin",
        "task_progress_metadata": [
            {
                "narration_text": "Cleans the kitchen table with a cloth",
                "start_frame": 87,
                "stop_frame": 113
            },
            {
                "narration_text": "Drops the dust on the cloth in the bin",
                "start_frame": 113,
                "stop_frame": 119
            },
            {
                "narration_text": "Shakes the cloth on top of the dust bin",
                "start_frame": 119,
                "stop_frame": 184
            }
        ]
    },
    {
        "task_goal": "Shaking the cloth over the dust bin",
        "task_progress_metadata": [
            {
                "narration_text": "Drops the dust on the cloth in the bin",
                "start_frame": 113,
                "stop_frame": 119
            },
            {
                "narration_text": "Shakes the cloth on top of the dust bin",
                "start_frame": 119,
                "stop_frame": 184
            },
            {
                "narration_text": "Cleans the kitchen table with a cloth",
                "start_frame": 184,
                "stop_frame": 264
            }
        ]
    },
    {
        "task_goal": "Cleaning the kitchen table again",
        "task_progress_metadata": [
            {
                "narration_text": "Shakes the cloth on top of the dust bin",
                "start_frame": 119,
                "stop_frame": 184
            },
            {
                "narration_text": "Cleans the kitchen table with a cloth",
                "start_frame": 184,
                "stop_frame": 264
            },
            {
                "narration_text": "Cleans the cooker on top of the table",
                "start_frame": 264,
                "stop_frame": 388
            }
        ]
    },
    {
        "task_goal": "Cleaning the cooker",
        "task_progress_metadata": [
            {
                "narration_text": "Cleans the kitchen table with a cloth",
                "start_frame": 184,
                "stop_frame": 264
            },
            {
                "narration_text": "Cleans the cooker on top of the table",
                "start_frame": 264,
                "stop_frame": 388
            },
            {
                "narration_text": "Drops the cloth on the kitchen table",
                "start_frame": 388,
                "stop_frame": 404
            }
        ]
    },
    {
        "task_goal": "Handling the cloth and the cooker",
        "task_progress_metadata": [
            {
                "narration_text": "Cleans the cooker on top of the table",
                "start_frame": 264,
                "stop_frame": 388
            },
            {
                "narration_text": "Drops the cloth on the kitchen table",
                "start_frame": 388,
                "stop_frame": 404
            },
            {
                "narration_text": "Drops unsure on the cooker",
                "start_frame": 404,
                "stop_frame": 424
            },
            {
                "narration_text": "Picks the cloth on top of the plastic tray on the table",
                "start_frame": 424,
                "stop_frame": 460
            },
            {
                "narration_text": "Places the cloth on the kitchen table",
                "start_frame": 460,
                "stop_frame": 470
            },
            {
                "narration_text": "Picks the cloth on the kitchen table",
                "start_frame": 470,
                "stop_frame": 493
            },
            {
                "narration_text": "Moves to the sink",
                "start_frame": 493,
                "stop_frame": 540
            },
            {
                "narration_text": "Opens the tap",
                "start_frame": 540,
                "stop_frame": 560
            }
        ]
    },
    {
        "task_goal": "Washing and rinsing the cloth and hands",
        "task_progress_metadata": [
            {
                "narration_text": "Moves to the sink",
                "start_frame": 493,
                "stop_frame": 540
            },
            {
                "narration_text": "Opens the tap",
                "start_frame": 540,
                "stop_frame": 560
            },
            {
                "narration_text": "Washes the cloth in the sink",
                "start_frame": 560,
                "stop_frame": 787
            },
            {
                "narration_text": "Rinses the cloth in the sink",
                "start_frame": 787,
                "stop_frame": 872
            },
            {
                "narration_text": "Rinses his hand in the sink",
                "start_frame": 872,
                "stop_frame": 967
            }
        ]
    },
    {
        "task_goal": "Starting and navigating through phone interfaces",
        "task_progress_metadata": [
            {
                "narration_text": "Rinses the cloth in the sink",
                "start_frame": 787,
                "stop_frame": 872
            },
            {
                "narration_text": "Rinses his hand in the sink",
                "start_frame": 872,
                "stop_frame": 967
            },
            {
                "narration_text": "Turns around",
                "start_frame": 967,
                "stop_frame": 1020
            },
            {
                "narration_text": "Places the clothing on the kitchen table",
                "start_frame": 1020,
                "stop_frame": 1111
            },
            {
                "narration_text": "Moves towards the cabinet",
                "start_frame": 1111,
                "stop_frame": 1178
            },
            {
                "narration_text": "Turns around",
                "start_frame": 1178,
                "stop_frame": 1395
            },
            {
                "narration_text": "Sits down on a plastic chair",
                "start_frame": 1395,
                "stop_frame": 1464
            },
            {
                "narration_text": "Moves a create on the floor",
                "start_frame": 1464,
                "stop_frame": 1663
            },
            {
                "narration_text": "Turns around",
                "start_frame": 1663,
                "stop_frame": 1685
            },
            {
                "narration_text": "Picks his phone on the table",
                "start_frame": 1685,
                "stop_frame": 1777
            },
            {
                "narration_text": "Taps his phones screen",
                "start_frame": 1777,
                "stop_frame": 2113
            }
        ]
    },
    {
        "task_goal": "Manipulating phone screen and holding phone",
        "task_progress_metadata": [
            {
                "narration_text": "Watches on phone in the right hand",
                "start_frame": 11553,
                "stop_frame": 12155
            },
            {
                "narration_text": "Raises right hand thumb from the phone screen",
                "start_frame": 12155,
                "stop_frame": 12324
            },
            {
                "narration_text": "Looks around",
                "start_frame": 12324,
                "stop_frame": 12423
            },
            {
                "narration_text": "Watches on phone in left hand",
                "start_frame": 12423,
                "stop_frame": 12501
            },
            {
                "narration_text": "Holds phone with both hands",
                "start_frame": 12501,
                "stop_frame": 12514
            },
            {
                "narration_text": "Places phone on the left knee",
                "start_frame": 12514,
                "stop_frame": 12669
            },
            {
                "narration_text": "Raises left hand",
                "start_frame": 12669,
                "stop_frame": 12706
            },
            {
                "narration_text": "Raises left hand",
                "start_frame": 12706,
                "stop_frame": 12731
            },
            {
                "narration_text": "Raises right hand",
                "start_frame": 12731,
                "stop_frame": 12815
            },
            {
                "narration_text": "Holds phone with both hands",
                "start_frame": 12815,
                "stop_frame": 12826
            },
            {
                "narration_text": "Stretches phone in both hands to the front",
                "start_frame": 12826,
                "stop_frame": 12891
            },
            {
                "narration_text": "Operates phone with right hand",
                "start_frame": 12891,
                "stop_frame": 12936
            },
            {
                "narration_text": "Watches on phone in both hands",
                "start_frame": 12936,
                "stop_frame": 13618
            },
            {
                "narration_text": "Operates phone with both hands",
                "start_frame": 13618,
                "stop_frame": 13852
            },
            {
                "narration_text": "Watches on phone in both hands",
                "start_frame": 13852,
                "stop_frame": 14089
            },
            {
                "narration_text": "Raises right hand thumb",
                "start_frame": 14089,
                "stop_frame": 14149
            },
            {
                "narration_text": "Watches on phone in both hands",
                "start_frame": 14149,
                "stop_frame": 14987
            }
        ]
    },
    {
        "task_goal": "Phone interactions including looking around",
        "task_progress_metadata": [
            {
                "narration_text": "Watches on phone in both hands",
                "start_frame": 14149,
                "stop_frame": 14987
            },
            {
                "narration_text": "Operates phone with right hand thumb",
                "start_frame": 14987,
                "stop_frame": 15203
            },
            {
                "narration_text": "Presses phone with right hand thumb",
                "start_frame": 15203,
                "stop_frame": 15312
            },
            {
                "narration_text": "Watches on phone in both hands",
                "start_frame": 15312,
                "stop_frame": 15423
            },
            {
                "narration_text": "Presses phone with right hand thumb",
                "start_frame": 15423,
                "stop_frame": 15519
            },
            {
                "narration_text": "Operates phone with right hand thumb",
                "start_frame": 15519,
                "stop_frame": 15581
            },
            {
                "narration_text": "Watches on phone in both hands",
                "start_frame": 15581,
                "stop_frame": 16553
            },
            {
                "narration_text": "Raises right hand thumb",
                "start_frame": 16553,
                "stop_frame": 16577
            },
            {
                "narration_text": "Watches on phone in both hands",
                "start_frame": 16577,
                "stop_frame": 17176
            },
            {
                "narration_text": "Removes the left hand from the phone",
                "start_frame": 17176,
                "stop_frame": 17203
            },
            {
                "narration_text": "Looks around",
                "start_frame": 17203,
                "stop_frame": 17236
            },
            {
                "narration_text": "Looks outside",
                "start_frame": 17236,
                "stop_frame": 17362
            },
            {
                "narration_text": "Looks at the phone",
                "start_frame": 17362,
                "stop_frame": 17436
            },
            {
                "narration_text": "Watches a game on a phone",
                "start_frame": 17436,
                "stop_frame": 19487
            },
            {
                "narration_text": "Presses the phone",
                "start_frame": 19487,
                "stop_frame": 19660
            },
            {
                "narration_text": "Watches a game on a phone",
                "start_frame": 19660,
                "stop_frame": 22053
            }
        ]
    },
    {
        "task_goal": "Returning to phone interactions",
        "task_progress_metadata": [
            {
                "narration_text": "Turns around",
                "start_frame": 28714,
                "stop_frame": 28837
            },
            {
                "narration_text": "Picks his phone from the cupboard",
                "start_frame": 28837,
                "stop_frame": 28916
            },
            {
                "narration_text": "Sits down",
                "start_frame": 28916,
                "stop_frame": 28998
            },
            {
                "narration_text": "Taps his phone",
                "start_frame": 28998,
                "stop_frame": 29086
            },
            {
                "narration_text": "Scrolls up his phone",
                "start_frame": 29086,
                "stop_frame": 30184
            },
            {
                "narration_text": "Selects a video in his phone",
                "start_frame": 30184,
                "stop_frame": 30463
            }
        ]
    },
    {
        "task_goal": "Watching a video, then placing phone down and interacting with environment",
        "task_progress_metadata": [
            {
                "narration_text": "Scrolls up his phone",
                "start_frame": 29086,
                "stop_frame": 30184
            },
            {
                "narration_text": "Selects a video in his phone",
                "start_frame": 30184,
                "stop_frame": 30463
            },
            {
                "narration_text": "Taps his phones screen",
                "start_frame": 30463,
                "stop_frame": 30509
            },
            {
                "narration_text": "Taps his phones screen",
                "start_frame": 30509,
                "stop_frame": 30652
            },
            {
                "narration_text": "Watches the video in his phone",
                "start_frame": 30652,
                "stop_frame": 31849
            },
            {
                "narration_text": "Looks outside the shops window",
                "start_frame": 31849,
                "stop_frame": 31945
            },
            {
                "narration_text": "Places his phone on the counter",
                "start_frame": 31945,
                "stop_frame": 32394
            },
            {
                "narration_text": "Looks outside the shop through the window",
                "start_frame": 32394,
                "stop_frame": 32502
            },
            {
                "narration_text": "Looks at the people in the parking outside his shop",
                "start_frame": 32502,
                "stop_frame": 33679
            },
            {
                "narration_text": "Lifts his hand",
                "start_frame": 33679,
                "stop_frame": 33760
            },
            {
                "narration_text": "Looks around",
                "start_frame": 33760,
                "stop_frame": 33798
            },
            {
                "narration_text": "Uses the phone",
                "start_frame": 33798,
                "stop_frame": 36029
            }
        ]
    },
    {
        "task_goal": "Cleaning and organizing kitchen items",
        "task_progress_metadata": []
    },
    {
        "task_goal": "Phone work and randomly handling other tasks in the environment",
        "task_progress_metadata": [
            {
                "narration_text": "Uses phone",
                "start_frame": 122317,
                "stop_frame": 125557
            },
            {
                "narration_text": "Does unsure with the left hand",
                "start_frame": 125557,
                "stop_frame": 125622
            },
            {
                "narration_text": "Moves around",
                "start_frame": 125622,
                "stop_frame": 125700
            },
            {
                "narration_text": "Places phone in a table",
                "start_frame": 125700,
                "stop_frame": 125722
            },
            {
                "narration_text": "Holds bottle with the right hand",
                "start_frame": 125722,
                "stop_frame": 125748
            },
            {
                "narration_text": "Looks around",
                "start_frame": 125748,
                "stop_frame": 125806
            },
            {
                "narration_text": "Does unsure",
                "start_frame": 125806,
                "stop_frame": 125915
            },
            {
                "narration_text": "Places bottle on the table",
                "start_frame": 125915,
                "stop_frame": 125957
            },
            {
                "narration_text": "Covers bottle with a lid",
                "start_frame": 125957,
                "stop_frame": 126043
            },
            {
                "narration_text": "Touches phone with the right hand",
                "start_frame": 126043,
                "stop_frame": 126112
            },
            {
                "narration_text": "Uses phone",
                "start_frame": 126112,
                "stop_frame": 126584
            },
            {
                "narration_text": "Picks phone from the table with the right hand",
                "start_frame": 126584,
                "stop_frame": 126600
            },
            {
                "narration_text": "Moves around the room",
                "start_frame": 126600,
                "stop_frame": 126718
            },
            {
                "narration_text": "Does unsure",
                "start_frame": 126718,
                "stop_frame": 126939
            },
            {
                "narration_text": "Uses phone",
                "start_frame": 126939,
                "stop_frame": 127039
            }
        ]
    },
    {
        "task_goal": "Phone engagement and constant observation",
        "task_progress_metadata": [
            {
                "narration_text": "Uses phone",
                "start_frame": 122317,
                "stop_frame": 125557
            },
            {
                "narration_text": "Does unsure with the left hand",
                "start_frame": 125557,
                "stop_frame": 125622
            },
            {
                "narration_text": "Moves around",
                "start_frame": 125622,
                "stop_frame": 125700
            },
            {
                "narration_text": "Places phone in a table",
                "start_frame": 125700,
                "stop_frame": 125722
            },
            {
                "narration_text": "Holds bottle with the right hand",
                "start_frame": 125722,
                "stop_frame": 125748
            },
            {
                "narration_text": "Looks around",
                "start_frame": 125748,
                "stop_frame": 125806
            },
            {
                "narration_text": "Does unsure",
                "start_frame": 125806,
                "stop_frame": 125915
            },
            {
                "narration_text": "Places bottle on the table",
                "start_frame": 125915,
                "stop_frame": 125957
            },
            {
                "narration_text": "Covers bottle with a lid",
                "start_frame": 125957,
                "stop_frame": 126043
            },
            {
                "narration_text": "Touches phone with the right hand",
                "start_frame": 126043,
                "stop_frame": 126112
            },
            {
                "narration_text": "Uses phone",
                "start_frame": 126112,
                "stop_frame": 126584
            },
            {
                "narration_text": "Picks phone from the table with the right hand",
                "start_frame": 126584,
                "stop_frame": 126600
            },
            {
                "narration_text": "Moves around the room",
                "start_frame": 126600,
                "stop_frame": 126718
            },
            {
                "narration_text": "Does unsure",
                "start_frame": 126718,
                "stop_frame": 126939
            },
            {
                "narration_text": "Uses phone",
                "start_frame": 126939,
                "stop_frame": 127039
            }
        ]
    },
    {
        "task_goal": "Engaging with environment and keeping organized",
        "task_progress_metadata": []
    }
]